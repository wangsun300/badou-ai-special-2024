# 推理和训练学习笔记

## 目录
1. 推理和训练
2. 训练的相关概念
3. 训练的步骤及涉及的问题
4. 手推训练过程

---

## 1. 推理和训练

### 1.1 监督学习与非监督学习

- **监督学习 (Supervised Learning)**: 输入的数据被称为训练数据，一个模型需要通过一个训练过程进行预期判断，如果错误了再进行修正，训练过程一直持续到基于训练数据达到预期的精确性。关键方法是分类和回归，如逻辑回归和BP神经网络。
- **非监督学习 (Unsupervised Learning)**: 没有任何训练数据，基于没有标记的输入数据采取推导结构的模型，关键方式是关联规则学习和聚类，比如k-means。

### 1.2 深度学习的推理和训练

- **训练 (Training)**: 一个初始神经网络通过不断优化自身参数，使其变得准确。
- **推理 (Inference)**: 训练好的模型在新的数据上进行识别或判断的过程。

---

## 2. 训练的相关概念

### 2.1 优化和泛化

- **优化 (Optimization)**: 调节模型以在训练数据上得到最佳性能。
- **泛化 (Generalization)**: 训练好的模型在未见过的数据上的表现。

### 2.2 数据集的分类

- **训练集**: 用于实际训练算法的数据集。
- **验证集**: 用于跟踪学习效果的数据集。
- **测试集**: 用于产生最终结果的数据集，不能用于训练网络。

### 2.3 交叉验证

- 将数据切成若干部分，每部分轮流做测试集，计算准确度并取平均值作为最终准确度。

---

## 3. 训练的步骤及涉及的问题

### 3.1 BP神经网络

- **BP网络**: 反向传播神经网络，是一种按误差逆向传播算法训练的多层前馈网络。
- **训练过程**: 包括正向传播和反向传播两个阶段。

### 3.2 神经网络的训练过程

1. **正向传播**: 输入信号从输入层经过隐藏层传播到输出层。
2. **反向传播**: 按照梯度下降方法调整神经元的连接权值和阈值。

### 3.3 训练过程中的关键概念

- **代 (Epoch)**: 使用训练集的全部数据对模型进行一次完整训练。
- **批大小 (Batch size)**: 使用训练集的一部分样本对模型权重进行一次反向传播更新。
- **迭代 (Iteration)**: 使用一个批数据对模型进行一次参数更新。

---

## 4. 手推训练过程

<embed src="手推.pdf" type="application/pdf" width="600" height="400">


### 4.1 参数初始化

- **随机初始化**: 防止所有参数相等导致高度冗余。

### 4.2 标准化 (Normalization)

- **原因**: 去除数据的单位限制，使不同单位或量级的指标能够比较和加权。
- **方法**: 数据归一化到[0,1]区间或零均值归一化。

### 4.3 损失函数

- **均方误差 (MSE)**: 常用于实数、无界的输入。
- **交叉熵 (Cross Entropy)**: 一般用于分类问题。

### 4.4 梯度下降法

- **梯度**: 指函数关于变量的导数。
- **学习率**: 控制调整神经网络权值的速度。

### 4.5 过拟合及其解决方法

- **过拟合**: 模型过分拟合训练数据，泛化能力差。
- **解决方法**: 减少特征、Early Stopping、增加训练样本、重新清洗数据、Dropout。

---

## 5. 常见问题

### 5.1 泛化能力分类

- **欠拟合**: 模型未能很好地表现数据结构。
- **过拟合**: 模型过分拟合训练样本，测试样本预测准确率低。
- **不收敛**: 模型训练过程中无法根据训练集得到稳定结果。

