# 1 层次聚类
## 是什么？
一层一层地进行聚类

分为凝聚的层次聚类算法和分裂的层次聚类

## 为什么要用层次聚类
解决了kmeans中需要事先设定k值的缺点

## 具体如何实现
```python
from scipy.cluster.hierarchy import dendrogram, linkage
from matplotlib import pyplot as plt

X = [[i] for i in [2, 8, 0, 4, 1, 9, 9, 0]]

# 计算类间距离，采用ward方差最小化算法
Z = linkage(X, 'ward')
fig = plt.figure(figsize=(25, 10))

# 将层次聚类编码为树状图的链接矩阵
dn = dendrogram(Z)

Z = linkage(X, 'single')
fig = plt.figure(figsize=(25, 10))
dn = dendrogram(Z)
plt.show()
```

### scipy.cluster.hierarchy.linkage
linkage(y, method=’single’, metric=’euclidean’)  
Parameters:
1. y：ndarray
	- 可以是1维压缩向量（距离向量），也可以是2维观测向量（坐标矩阵）
	- 若y是1维压缩向量，则y必须是n个初始观测值的组合，n是坐标矩阵中成对的观测值。  
2. method：str
	- 计算类间距离的方法
3. metric：str or Function
	- 在y是观测向量的集合的情况下使用的距离度量

Returns:
1. Z：ndarray
	- 编码为链接矩阵的层次聚类

### scipy.cluster.hierarchy.fcluster
fcluster(Z, t, criterion=’inconsistent’, depth=2, R=None, monocrit=None)  
Parameters:
1. Z：ndarray
	- 是linkage得到的矩阵,记录了层次聚类的层次信息;
2. t：scalar
	- 是一个聚类的阈值-“The threshold to apply when forming flat clusters”
3. criterion：str
	- 用于形成flat clusters的标准
		`inconsistent` ：(Default) 如果集群节点及其所有子节点的值不一致，小于或等于t，则其所有叶子节点属于同一平面集群。当没有非单例集群满足这一标准时，每个节点都被分配到自己的集群。
		
1. depth：int
	- 执行不一致性计算的最大深度。它对其他条件没有意义。默认值为2。
2. R：ndarray
	1. 用于“不一致”标准的不一致性矩阵
3. monocrit：ndarray

Returns:
  - fcluster：adarray

### scipy.cluster.hierarchy.dendrogram
dendrogram(_Z_, _p=30_,)
Parameters:
1. Z：ndarray
	- 将层次聚类编码为树状图的链接矩阵

Returns:
1. R：dict

# 2 密度聚类DBSCAN
## 是什么？
需要两个参数：ε(eps) 和 形成高密度区域所需要的最少点数(minPts)

## 为什么要用密度聚类
对噪声不敏感

## 具体如何实现？
```python
import matplotlib.pyplot as plt  
import numpy as np  
from sklearn import datasets  
from sklearn.cluster import DBSCAN

iris = datasets.load_iris()  
X = iris.data[:, :4]  # 表示我们只取特征空间中的4个维度  
print(X.shape)

dbscan = DBSCAN(eps=0.4, min_samples=9)  
dbscan.fit(X)  
label_pred = dbscan.labels_

# 绘制结果  
x0 = X[label_pred == 0]  
x1 = X[label_pred == 1]  
x2 = X[label_pred == 2]  
plt.scatter(x0[:, 0], x0[:, 1], c="red", marker='o', label='label0')  
plt.scatter(x1[:, 0], x1[:, 1], c="green", marker='*', label='label1')  
plt.scatter(x2[:, 0], x2[:, 1], c="blue", marker='+', label='label2')  
plt.xlabel('sepal length')  
plt.ylabel('sepal width')  
plt.legend(loc=2)  
plt.show()
```
### DBSCAN
`DBSCAN(eps=0.5, *, min_samples=5, metric='euclidean', metric_params=None, algorithm='auto', leaf_size=30, p=None, n_jobs=None)`

Parameters:
1. eps：float, default=0.5
	- 两个样本之间的最大距离，其中一个样本被视为在另一个样本的邻域内。这不是簇内点距离的最大界限。这是为数据集和距离函数适当选择的最重要的DBSCAN参数。
2. min_samples：int, default=5
	- 将某个点视为核心点的邻域中的样本数（或总权重）。这包括要点本身。如果min_samples设置为更高的值，DBSCAN将发现更密集的簇，而如果设置为更低的值，则发现的簇将更稀疏。
3. metric：str, or callable, default=’euclidean’
	- 计算要素阵列中实例之间的距离时要使用的度量。如果metric是字符串或可调用，则它必须是sklearn.metrics.pairwise_dinstances为其metric参数所允许的选项之一。若度量是“预先计算的”，则假定X是一个距离矩阵，并且必须是平方。X可以是稀疏图，在这种情况下，只有“非零”元素可以被认为是DBSCAN的邻居。
4. metric_params：dict, default=None
	- 度量函数的其他关键字参数。
5. algorithm：{‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}, default=’auto’
	- 最近邻居模块用于计算逐点距离和查找最近邻居的算法。
6. leaf_size：int, default=30
	- 传递给BallTree或cKDTree的叶大小。这可能会影响构建和查询的速度，以及存储树所需的内存。最优值取决于问题的性质。
7. p：float, default=None
	- 用于计算点之间距离的Minkowski度量的幂。如果无，则p=2（相当于欧几里得距离）。
8. n_jobs：int, default=None
	- 要运行的并行作业数。None表示1，除非在joblib.paralle_backend上下文中-1表示使用所有处理器

`fit(_X_, _y=None_, _sample_weight=None_)`

Parameters:
1. X：{array-like, sparse matrix} of shape (n_samples, n_features), or (n_samples, n_samples)
	- 将实例训练到集群，或者如果metric=“重新计算”，则训练实例之间的距离。

# 3 SIFT—尺度不变特征变换

## 是什么？
在不同尺度空间上查找关键点（特征点），计算关键点的大小、方向、尺度信息，利用这些信息组成关键点对特征点进行描述

## 为什么要用SIFT
物体辨别、机器人地图感知与导航、影像拼接、3D模型建立、手势识别、影像追踪

课程中讲到的：实现图像的拼接

## 怎么用？
具体步骤
1. 尺度空间极值检测 (Scale-space Extrema Detection)
2. 点定位 (Keypoint Localization)
3. 定向任务 (Orientation Assignment)
4. 关键点描述 (Keypoint Descriptor)
5. 关键点匹配 (Keypoint Matching)

### 用法1：寻找关键点
```python
import numpy as np
import cv2 as cv

img = cv.imread('home.jpg')

gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)

# 创建SIFT对象
sift = cv.SIFT_create()
kp = sift.detect(gray, None)
img = cv.drawKeypoints(image=gray, kp, outImage=img)

cv.imwrite('sift_keypoints.jpg', img)
```

#### sift.detect()
`sift.detect()`

函数在图像中查找关键点。如果只想搜索图像的一部分，可以传递遮罩。每个关键点都是一个特殊的结构，具有许多属性，如其（x，y）坐标、有意义邻域的大小、指定其方向的角度、指定关键点强度的响应等。

#### cv.drawKeypoints()
`img=cv.drawKeypoints(gray,kp,img,flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)`

cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS：对图像的每个关键点都绘制了圆圈和方向

在关键点的位置上绘制小圆圈

### 用法2：特征匹配
```python
import numpy as np
import cv2 as cv
import matplotlib.pyplot as plt

img1 = cv.imread('iphone1.png', cv.IMREAD_GRAYSCALE)  # queryImage
img2 = cv.imread('iphone2.png', cv.IMREAD_GRAYSCALE)  # trainImage

# 初始化ORB detector
orb = cv.ORB_create()

# 用ORB找到关键点和描述符
kp1, des1 = orb.detectAndCompute(img1, None)
kp2, des2 = orb.detectAndCompute(img2, None)

# 创建BFMatcher对象
bf = cv.BFMatcher(cv.NORM_HAMMING, crossCheck=True)  # 打开交叉验证

# 获取两个图像中的最佳匹配
matches = bf.match(des1, des2)

# 按照距离的升序对其进行排列
matches = sorted(matches, key = lambda x:x.distance)

# 画出前10个最佳匹配
img3 = cv.drawMatches(img1, kp1, img2, kp2, matches[:10], None, flags=cv.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

plt.imshow(img3), plt.show()
```
